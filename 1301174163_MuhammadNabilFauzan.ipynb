{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1301174163_MuhammadNabilFauzan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkrI6L6pq5Oo"
      },
      "source": [
        "# This is an implementation of TF-IDF based on the following link\n",
        "# https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
        "# If you failed to access the web page, you might access the pdf file in the following link\n",
        "# https://drive.google.com/file/d/1J7J6p8hZ3lDmncxq1f6HHNstaGbtREHj/view?usp=sharing\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqTGvL4ErEwv",
        "outputId": "7d148169-8d03-42aa-8775-c7f6822be4d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Simple documents\n",
        "# Change the content, so you can have some intuition about TF-IDF\n",
        "\n",
        "documentA = 'Bukan aku yang mencarimu Bukan kamu yang mencari aku Cinta yang mempertemukan Dua hati yang berbeda ini'\n",
        "documentB = 'Saat kau terlalu rapuh Pundak siapa yang tersandar Tangan siapa yang tak melepas Ku yakin aku'\n",
        "documentC = 'Aku yang minta maaf walau kau yang salah Aku kan menahan walau kau ingin pisah Karna kamu penting Lebih penting Dari semua yang ku punya'\n",
        "\n",
        "# documentA = 'The TF-IDF are than obtained by multiplying the TF of each document (item) with the IDF which applicable globally'\n",
        "# documentB = 'The TF-IDF values represent the vector of each item'\n",
        "# documentC = 'By using the cosine similarity or other distance techniques we can calculate similar items, or group the items into several clusters'\n",
        "# documentD = 'Therefore, we can use TF-IDF as an algorithm in Content Based Filtering'\n",
        "\n",
        "# split each document\n",
        "bagOfWordsA = documentA.split(' ')\n",
        "bagOfWordsB = documentB.split(' ')\n",
        "bagOfWordsC = documentC.split(' ')\n",
        "\n",
        "print(bagOfWordsA)\n",
        "print(bagOfWordsB)\n",
        "print(bagOfWordsC)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bukan', 'aku', 'yang', 'mencarimu', 'Bukan', 'kamu', 'yang', 'mencari', 'aku', 'Cinta', 'yang', 'mempertemukan', 'Dua', 'hati', 'yang', 'berbeda', 'ini']\n",
            "['Saat', 'kau', 'terlalu', 'rapuh', 'Pundak', 'siapa', 'yang', 'tersandar', 'Tangan', 'siapa', 'yang', 'tak', 'melepas', 'Ku', 'yakin', 'aku']\n",
            "['Aku', 'yang', 'minta', 'maaf', 'walau', 'kau', 'yang', 'salah', 'Aku', 'kan', 'menahan', 'walau', 'kau', 'ingin', 'pisah', 'Karna', 'kamu', 'penting', 'Lebih', 'penting', 'Dari', 'semua', 'yang', 'ku', 'punya']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RsDY8knrHxn",
        "outputId": "b773db75-6744-4d4f-f79f-bc3588808ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Find the uniue set of words\n",
        "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB)).union(set(bagOfWordsC))\n",
        "print(uniqueWords)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'berbeda', 'tersandar', 'tak', 'pisah', 'punya', 'ingin', 'Cinta', 'aku', 'yakin', 'Dua', 'mencari', 'kau', 'penting', 'Karna', 'ku', 'Saat', 'maaf', 'kan', 'salah', 'Dari', 'Aku', 'walau', 'menahan', 'mempertemukan', 'minta', 'melepas', 'Pundak', 'yang', 'mencarimu', 'Tangan', 'hati', 'Ku', 'semua', 'ini', 'terlalu', 'Lebih', 'Bukan', 'siapa', 'kamu', 'rapuh'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns3rZpOUrKom",
        "outputId": "586a676f-4a33-4f00-bb4d-176a8a5ca4c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create dictionary for each document and calculate the word frequency in each document\n",
        "\n",
        "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsA:\n",
        "    numOfWordsA[word] += 1\n",
        "print(numOfWordsA)\n",
        "\n",
        "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsB:\n",
        "    numOfWordsB[word] += 1\n",
        "print(numOfWordsB)\n",
        "\n",
        "numOfWordsC = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsC:\n",
        "    numOfWordsC[word] += 1\n",
        "print(numOfWordsC)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'berbeda': 1, 'tersandar': 0, 'tak': 0, 'pisah': 0, 'punya': 0, 'ingin': 0, 'Cinta': 1, 'aku': 2, 'yakin': 0, 'Dua': 1, 'mencari': 1, 'kau': 0, 'penting': 0, 'Karna': 0, 'ku': 0, 'Saat': 0, 'maaf': 0, 'kan': 0, 'salah': 0, 'Dari': 0, 'Aku': 0, 'walau': 0, 'menahan': 0, 'mempertemukan': 1, 'minta': 0, 'melepas': 0, 'Pundak': 0, 'yang': 4, 'mencarimu': 1, 'Tangan': 0, 'hati': 1, 'Ku': 0, 'semua': 0, 'ini': 1, 'terlalu': 0, 'Lebih': 0, 'Bukan': 2, 'siapa': 0, 'kamu': 1, 'rapuh': 0}\n",
            "{'berbeda': 0, 'tersandar': 1, 'tak': 1, 'pisah': 0, 'punya': 0, 'ingin': 0, 'Cinta': 0, 'aku': 1, 'yakin': 1, 'Dua': 0, 'mencari': 0, 'kau': 1, 'penting': 0, 'Karna': 0, 'ku': 0, 'Saat': 1, 'maaf': 0, 'kan': 0, 'salah': 0, 'Dari': 0, 'Aku': 0, 'walau': 0, 'menahan': 0, 'mempertemukan': 0, 'minta': 0, 'melepas': 1, 'Pundak': 1, 'yang': 2, 'mencarimu': 0, 'Tangan': 1, 'hati': 0, 'Ku': 1, 'semua': 0, 'ini': 0, 'terlalu': 1, 'Lebih': 0, 'Bukan': 0, 'siapa': 2, 'kamu': 0, 'rapuh': 1}\n",
            "{'berbeda': 0, 'tersandar': 0, 'tak': 0, 'pisah': 1, 'punya': 1, 'ingin': 1, 'Cinta': 0, 'aku': 0, 'yakin': 0, 'Dua': 0, 'mencari': 0, 'kau': 2, 'penting': 2, 'Karna': 1, 'ku': 1, 'Saat': 0, 'maaf': 1, 'kan': 1, 'salah': 1, 'Dari': 1, 'Aku': 2, 'walau': 2, 'menahan': 1, 'mempertemukan': 0, 'minta': 1, 'melepas': 0, 'Pundak': 0, 'yang': 3, 'mencarimu': 0, 'Tangan': 0, 'hati': 0, 'Ku': 0, 'semua': 1, 'ini': 0, 'terlalu': 0, 'Lebih': 1, 'Bukan': 0, 'siapa': 0, 'kamu': 1, 'rapuh': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZRjogYlrNXB",
        "outputId": "aeb0a4bf-bdbc-4525-c166-1aa35c34a308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#importing stopword\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "#stopwords.words('english')\n",
        "stopwords"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<WordListCorpusReader in '/root/nltk_data/corpora/stopwords'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWbH7FuQrQaD",
        "outputId": "c73d61e8-9b32-481a-f1d6-580052a3c0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute the Term Frequency\n",
        "def computeTF(wordDict, bagOfWords):\n",
        "    tfDict = {}\n",
        "    bagOfWordsCount = len(bagOfWords)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bagOfWordsCount)\n",
        "    return tfDict\n",
        "\n",
        "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
        "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
        "tfC = computeTF(numOfWordsC, bagOfWordsC)\n",
        "\n",
        "print(tfA)\n",
        "print(tfB)\n",
        "print(tfC)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'berbeda': 0.058823529411764705, 'tersandar': 0.0, 'tak': 0.0, 'pisah': 0.0, 'punya': 0.0, 'ingin': 0.0, 'Cinta': 0.058823529411764705, 'aku': 0.11764705882352941, 'yakin': 0.0, 'Dua': 0.058823529411764705, 'mencari': 0.058823529411764705, 'kau': 0.0, 'penting': 0.0, 'Karna': 0.0, 'ku': 0.0, 'Saat': 0.0, 'maaf': 0.0, 'kan': 0.0, 'salah': 0.0, 'Dari': 0.0, 'Aku': 0.0, 'walau': 0.0, 'menahan': 0.0, 'mempertemukan': 0.058823529411764705, 'minta': 0.0, 'melepas': 0.0, 'Pundak': 0.0, 'yang': 0.23529411764705882, 'mencarimu': 0.058823529411764705, 'Tangan': 0.0, 'hati': 0.058823529411764705, 'Ku': 0.0, 'semua': 0.0, 'ini': 0.058823529411764705, 'terlalu': 0.0, 'Lebih': 0.0, 'Bukan': 0.11764705882352941, 'siapa': 0.0, 'kamu': 0.058823529411764705, 'rapuh': 0.0}\n",
            "{'berbeda': 0.0, 'tersandar': 0.0625, 'tak': 0.0625, 'pisah': 0.0, 'punya': 0.0, 'ingin': 0.0, 'Cinta': 0.0, 'aku': 0.0625, 'yakin': 0.0625, 'Dua': 0.0, 'mencari': 0.0, 'kau': 0.0625, 'penting': 0.0, 'Karna': 0.0, 'ku': 0.0, 'Saat': 0.0625, 'maaf': 0.0, 'kan': 0.0, 'salah': 0.0, 'Dari': 0.0, 'Aku': 0.0, 'walau': 0.0, 'menahan': 0.0, 'mempertemukan': 0.0, 'minta': 0.0, 'melepas': 0.0625, 'Pundak': 0.0625, 'yang': 0.125, 'mencarimu': 0.0, 'Tangan': 0.0625, 'hati': 0.0, 'Ku': 0.0625, 'semua': 0.0, 'ini': 0.0, 'terlalu': 0.0625, 'Lebih': 0.0, 'Bukan': 0.0, 'siapa': 0.125, 'kamu': 0.0, 'rapuh': 0.0625}\n",
            "{'berbeda': 0.0, 'tersandar': 0.0, 'tak': 0.0, 'pisah': 0.04, 'punya': 0.04, 'ingin': 0.04, 'Cinta': 0.0, 'aku': 0.0, 'yakin': 0.0, 'Dua': 0.0, 'mencari': 0.0, 'kau': 0.08, 'penting': 0.08, 'Karna': 0.04, 'ku': 0.04, 'Saat': 0.0, 'maaf': 0.04, 'kan': 0.04, 'salah': 0.04, 'Dari': 0.04, 'Aku': 0.08, 'walau': 0.08, 'menahan': 0.04, 'mempertemukan': 0.0, 'minta': 0.04, 'melepas': 0.0, 'Pundak': 0.0, 'yang': 0.12, 'mencarimu': 0.0, 'Tangan': 0.0, 'hati': 0.0, 'Ku': 0.0, 'semua': 0.04, 'ini': 0.0, 'terlalu': 0.0, 'Lebih': 0.04, 'Bukan': 0.0, 'siapa': 0.0, 'kamu': 0.04, 'rapuh': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji6rhfBSrTXe",
        "outputId": "3c581a5e-3e2f-4281-c32c-a50992571661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute the inverse document frequency\n",
        "def computeIDF(documents):\n",
        "    import math\n",
        "    N = len(documents)\n",
        "    \n",
        "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
        "    for document in documents:\n",
        "        for word, val in document.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log(N / float(val))\n",
        "    return idfDict\n",
        "\n",
        "idfs = computeIDF([numOfWordsA, numOfWordsB, numOfWordsC])\n",
        "print(idfs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'berbeda': 1.0986122886681098, 'tersandar': 1.0986122886681098, 'tak': 1.0986122886681098, 'pisah': 1.0986122886681098, 'punya': 1.0986122886681098, 'ingin': 1.0986122886681098, 'Cinta': 1.0986122886681098, 'aku': 0.4054651081081644, 'yakin': 1.0986122886681098, 'Dua': 1.0986122886681098, 'mencari': 1.0986122886681098, 'kau': 0.4054651081081644, 'penting': 1.0986122886681098, 'Karna': 1.0986122886681098, 'ku': 1.0986122886681098, 'Saat': 1.0986122886681098, 'maaf': 1.0986122886681098, 'kan': 1.0986122886681098, 'salah': 1.0986122886681098, 'Dari': 1.0986122886681098, 'Aku': 1.0986122886681098, 'walau': 1.0986122886681098, 'menahan': 1.0986122886681098, 'mempertemukan': 1.0986122886681098, 'minta': 1.0986122886681098, 'melepas': 1.0986122886681098, 'Pundak': 1.0986122886681098, 'yang': 0.0, 'mencarimu': 1.0986122886681098, 'Tangan': 1.0986122886681098, 'hati': 1.0986122886681098, 'Ku': 1.0986122886681098, 'semua': 1.0986122886681098, 'ini': 1.0986122886681098, 'terlalu': 1.0986122886681098, 'Lebih': 1.0986122886681098, 'Bukan': 1.0986122886681098, 'siapa': 1.0986122886681098, 'kamu': 0.4054651081081644, 'rapuh': 1.0986122886681098}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzTvsp51rWVb",
        "outputId": "cc665bdd-ab96-42a2-b81f-897fdfbe5c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "# Compute the TFxIDF\n",
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagOfWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf\n",
        "\n",
        "tfidfA = computeTFIDF(tfA, idfs)\n",
        "tfidfB = computeTFIDF(tfB, idfs)\n",
        "tfidfC = computeTFIDF(tfC, idfs)\n",
        "df = pd.DataFrame([tfidfA, tfidfB, tfidfC])\n",
        "\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>berbeda</th>\n",
              "      <th>tersandar</th>\n",
              "      <th>tak</th>\n",
              "      <th>pisah</th>\n",
              "      <th>punya</th>\n",
              "      <th>ingin</th>\n",
              "      <th>Cinta</th>\n",
              "      <th>aku</th>\n",
              "      <th>yakin</th>\n",
              "      <th>Dua</th>\n",
              "      <th>mencari</th>\n",
              "      <th>kau</th>\n",
              "      <th>penting</th>\n",
              "      <th>Karna</th>\n",
              "      <th>ku</th>\n",
              "      <th>Saat</th>\n",
              "      <th>maaf</th>\n",
              "      <th>kan</th>\n",
              "      <th>salah</th>\n",
              "      <th>Dari</th>\n",
              "      <th>Aku</th>\n",
              "      <th>walau</th>\n",
              "      <th>menahan</th>\n",
              "      <th>mempertemukan</th>\n",
              "      <th>minta</th>\n",
              "      <th>melepas</th>\n",
              "      <th>Pundak</th>\n",
              "      <th>yang</th>\n",
              "      <th>mencarimu</th>\n",
              "      <th>Tangan</th>\n",
              "      <th>hati</th>\n",
              "      <th>Ku</th>\n",
              "      <th>semua</th>\n",
              "      <th>ini</th>\n",
              "      <th>terlalu</th>\n",
              "      <th>Lebih</th>\n",
              "      <th>Bukan</th>\n",
              "      <th>siapa</th>\n",
              "      <th>kamu</th>\n",
              "      <th>rapuh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.047702</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129249</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023851</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025342</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032437</td>\n",
              "      <td>0.087889</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.087889</td>\n",
              "      <td>0.087889</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016219</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    berbeda  tersandar       tak  ...     siapa      kamu     rapuh\n",
              "0  0.064624   0.000000  0.000000  ...  0.000000  0.023851  0.000000\n",
              "1  0.000000   0.068663  0.068663  ...  0.137327  0.000000  0.068663\n",
              "2  0.000000   0.000000  0.000000  ...  0.000000  0.016219  0.000000\n",
              "\n",
              "[3 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APHHaezrrZKz",
        "outputId": "63a40097-21ab-488d-ccd8-78241e7710a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "# Obtaining TF-IDF using sklearn library\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([documentA, documentB, documentC])\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "dense = vectors.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist, columns=feature_names)\n",
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aku</th>\n",
              "      <th>berbeda</th>\n",
              "      <th>bukan</th>\n",
              "      <th>cinta</th>\n",
              "      <th>dari</th>\n",
              "      <th>dua</th>\n",
              "      <th>hati</th>\n",
              "      <th>ingin</th>\n",
              "      <th>ini</th>\n",
              "      <th>kamu</th>\n",
              "      <th>kan</th>\n",
              "      <th>karna</th>\n",
              "      <th>kau</th>\n",
              "      <th>ku</th>\n",
              "      <th>lebih</th>\n",
              "      <th>maaf</th>\n",
              "      <th>melepas</th>\n",
              "      <th>mempertemukan</th>\n",
              "      <th>menahan</th>\n",
              "      <th>mencari</th>\n",
              "      <th>mencarimu</th>\n",
              "      <th>minta</th>\n",
              "      <th>penting</th>\n",
              "      <th>pisah</th>\n",
              "      <th>pundak</th>\n",
              "      <th>punya</th>\n",
              "      <th>rapuh</th>\n",
              "      <th>saat</th>\n",
              "      <th>salah</th>\n",
              "      <th>semua</th>\n",
              "      <th>siapa</th>\n",
              "      <th>tak</th>\n",
              "      <th>tangan</th>\n",
              "      <th>terlalu</th>\n",
              "      <th>tersandar</th>\n",
              "      <th>walau</th>\n",
              "      <th>yakin</th>\n",
              "      <th>yang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.267120</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.452274</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.171983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.226137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.148113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190723</td>\n",
              "      <td>0.190723</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501555</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.250778</td>\n",
              "      <td>0.296227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.223211</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143713</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.287425</td>\n",
              "      <td>0.143713</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.37793</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.188965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.37793</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.334817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        aku   berbeda     bukan  ...    walau     yakin      yang\n",
              "0  0.267120  0.226137  0.452274  ...  0.00000  0.000000  0.534241\n",
              "1  0.148113  0.000000  0.000000  ...  0.00000  0.250778  0.296227\n",
              "2  0.223211  0.000000  0.000000  ...  0.37793  0.000000  0.334817\n",
              "\n",
              "[3 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUcnZ79YYjpU"
      },
      "source": [
        "# Tugas Besar 1 Implementasi Content Based Filtering dengan TF-IDF.\n",
        "# a. Copy lirik \"Reff\" dari lagu berbahasa Indonesia (masing-masing 3 lagu), \n",
        "# b. Paste ke link berikut (Pastikan 1 lagu 1 cell lirik_ref): \n",
        "# https://docs.google.com/spreadsheets/d/1j98gjzwL-88GPiTGkRgEWhWWcKryvNAdlaDR_oBWgpY/edit?usp=sharing\n",
        "# c. Cari informasi mengenai k-NN, dan yang diimplementasikan pada TF-IDF pada dataset di atas\n",
        "# d. Buat satu prosedur yang menerima ID dari lagu, dan kembalikan 5 ID most-similar items"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtSWkHZty2ch"
      },
      "source": [
        "df2 = df.transpose()\n",
        "newdf = pd.DataFrame(columns=['words', 'vectorizer'])\n",
        "newdf['words'] = df2.index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b75PDq--THG",
        "outputId": "07e5f9ca-a260-4c4d-d72b-d64b750c5a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "newdf['vectorizer'] = newdf['vectorizer'].fillna('')\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(newdf['words'])\n",
        "\n",
        "tfidf_matrix.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gETRymrzUr-e"
      },
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qpJ8pj8VC2A"
      },
      "source": [
        "indices = pd.Series(newdf.index, index=newdf['words']).drop_duplicates()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWxxw5LWWHGf"
      },
      "source": [
        "def get_recommendations(title, cosine_sim = cosine_sim):\n",
        "  idx = indices[title]\n",
        "  sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  sim_scores = sim_scores[1:6]\n",
        "  movie_indices = [i[0] for i in sim_scores]\n",
        "  return newdf['words'].iloc[movie_indices]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PBawaYpXhN8",
        "outputId": "695b724a-ff7d-4bbf-df67-7460ed321b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_recommendations('kau')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        aku\n",
              "1    berbeda\n",
              "2      bukan\n",
              "3      cinta\n",
              "4       dari\n",
              "Name: words, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}